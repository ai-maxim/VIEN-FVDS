## Master-Class to Archipelag 2035 on Generative Adversarial Networks

## Art painting enhance using by NVidia StyleGAN2
Jupyter Notebook art enhaning pipe with scripts to train Stylegan2 models on new data from scratch or via transfer learning. Also contains scripts for generating images from trained models, and projecting images onto the generatable manifold.This notebook is an extension of [Mikael Christensen's notebook](https://colab.research.google.com/drive/1ShgW6wohEFQtqs_znMna3dzrcVoABKIH#scrollTo=4_s8h-ilzHQc), and includes his scripts for image generation and projection.

[Link to Google Colab Notebook](https://colab.research.google.com/drive/1n1MF26_UuySphQ3oZptVycigrZBTbMjK)

## StyleGAN2 &mdash; Official TensorFlow Implementation

![Teaser image](./docs/stylegan2-teaser-1024x256.png)

**Analyzing and Improving the Image Quality of StyleGAN**<br>
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila<br>


Theoretical part:
- Tasks and methods of optimization
- Lagrange multiplier method
- Newton's method

Video: https://youtu.be/TXPdZTJ36fY<br>

Abstract: *The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven unconditional generative image modeling. We expose and analyze several of its characteristic artifacts, and propose changes in both model architecture and training methods to address them. In particular, we redesign generator normalization, revisit progressive growing, and regularize the generator to encourage good conditioning in the mapping from latent vectors to images. In addition to improving image quality, this path length regularizer yields the additional benefit that the generator becomes significantly easier to invert. This makes it possible to reliably detect if an image is generated by a particular network. We furthermore visualize how well the generator utilizes its output resolution, and identify a capacity problem, motivating us to train larger models for additional quality improvements. Overall, our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived image quality.*

For business inquiries, please contact [researchinquiries@nvidia.com](mailto:researchinquiries@nvidia.com)<br>
For press and other inquiries, please contact Hector Marinez at [hmarinez@nvidia.com](mailto:hmarinez@nvidia.com)<br>
